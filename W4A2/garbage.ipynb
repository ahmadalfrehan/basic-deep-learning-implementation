{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean   \n",
       "0    842302         M        17.99         10.38          122.80     1001.0  \\\n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "7  84458202         M        13.71         20.83           90.20      577.9   \n",
       "8    844981         M        13.00         21.82           87.50      519.8   \n",
       "9  84501001         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean   \n",
       "0          0.11840           0.27760         0.30010              0.14710  \\\n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst   \n",
       "0  ...          17.33           184.60      2019.0            0.1622  \\\n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "5  ...          23.75           103.40       741.6            0.1791   \n",
       "6  ...          27.66           153.20      1606.0            0.1442   \n",
       "7  ...          28.14           110.60       897.0            0.1654   \n",
       "8  ...          30.73           106.20       739.3            0.1703   \n",
       "9  ...          40.68            97.65       711.4            0.1853   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst   \n",
       "0             0.6656           0.7119                0.2654          0.4601  \\\n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "5             0.5249           0.5355                0.1741          0.3985   \n",
       "6             0.2576           0.3784                0.1932          0.3063   \n",
       "7             0.3682           0.2678                0.1556          0.3196   \n",
       "8             0.5401           0.5390                0.2060          0.4378   \n",
       "9             1.0580           1.1050                0.2210          0.4366   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "5                  0.12440          NaN  \n",
       "6                  0.08368          NaN  \n",
       "7                  0.11510          NaN  \n",
       "8                  0.10720          NaN  \n",
       "9                  0.20750          NaN  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('archive/Cancer_Data.csv')\n",
    "df.head(10)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_val</th>\n",
       "      <th>missing_val_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <td>569</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         missing_val  missing_val_ratio\n",
       "id                                 0                  0\n",
       "diagnosis                          0                  0\n",
       "radius_mean                        0                  0\n",
       "texture_mean                       0                  0\n",
       "perimeter_mean                     0                  0\n",
       "area_mean                          0                  0\n",
       "smoothness_mean                    0                  0\n",
       "compactness_mean                   0                  0\n",
       "concavity_mean                     0                  0\n",
       "concave points_mean                0                  0\n",
       "symmetry_mean                      0                  0\n",
       "fractal_dimension_mean             0                  0\n",
       "radius_se                          0                  0\n",
       "texture_se                         0                  0\n",
       "perimeter_se                       0                  0\n",
       "area_se                            0                  0\n",
       "smoothness_se                      0                  0\n",
       "compactness_se                     0                  0\n",
       "concavity_se                       0                  0\n",
       "concave points_se                  0                  0\n",
       "symmetry_se                        0                  0\n",
       "fractal_dimension_se               0                  0\n",
       "radius_worst                       0                  0\n",
       "texture_worst                      0                  0\n",
       "perimeter_worst                    0                  0\n",
       "area_worst                         0                  0\n",
       "smoothness_worst                   0                  0\n",
       "compactness_worst                  0                  0\n",
       "concavity_worst                    0                  0\n",
       "concave points_worst               0                  0\n",
       "symmetry_worst                     0                  0\n",
       "fractal_dimension_worst            0                  0\n",
       "Unnamed: 32                      569                100"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "info_df = pd.DataFrame()\n",
    "info_df['missing_val'] = df.isnull().sum()\n",
    "info_df['missing_val_ratio'] = (info_df['missing_val'] / df.shape[0] * 100).round().astype(int)\n",
    "info_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 32'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         B      M\n",
       "0    False   True\n",
       "1    False   True\n",
       "2    False   True\n",
       "3    False   True\n",
       "4    False   True\n",
       "..     ...    ...\n",
       "564  False   True\n",
       "565  False   True\n",
       "566  False   True\n",
       "567  False   True\n",
       "568   True  False\n",
       "\n",
       "[569 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df['diagnosis']\n",
    "pd.get_dummies(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer \n",
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(s) # need to be global or remembered to use it later\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    return label_binarizer.transform(x)  \n",
    "d = one_hot_encode(s)       \n",
    "df['label_encoding'] = d+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_encoding\n",
       "1    357\n",
       "2    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_encoding'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = df[['area_se', 'perimeter_se', 'radius_se', 'compactness_worst',\n",
    "       'compactness_mean', 'concavity_worst', 'concavity_mean', 'area_mean',\n",
    "       'radius_mean', 'area_worst', 'perimeter_mean', 'radius_worst',\n",
    "       'concave points_mean', 'perimeter_worst', 'concave points_worst']]\n",
    "                  \n",
    "# Define y_raw as the 'diagnosis' column                  \n",
    "y = df['label_encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of feature inputs are within 0.0 to 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scaling the raw input features\n",
    "X = scaler.fit_transform(X_raw)\n",
    "\n",
    "#schecking what we done\n",
    "print(f\"The range of feature inputs are within {X.min()} to {X.max()}\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 15)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 455)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_dims = [15, 10, 5, 1]\n",
    "X_train_transposed = X_train.T\n",
    "y_train_transposed = y_train.values.reshape(1, -1)\n",
    "X_train_transposed.shape\n",
    "y_train_transposed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_app_utils_v3 import *\n",
    "from public_tests import *\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    costs = []  \n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, caches = L_model_forward(X,parameters)\n",
    "        m = Y.shape[1]\n",
    "        AL = np.clip(AL, 1e-10, 1 - 1e-10)\n",
    "        cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "\n",
    "        cost = np.squeeze(cost)\n",
    "    \n",
    "        grads = L_model_backward(AL,Y,caches)\n",
    "        parameters = update_parameters(parameters,grads,learning_rate)\n",
    "        \n",
    "        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: -8.60306515156377\n",
      "Cost after iteration 100: -8.60306515156377\n",
      "Cost after iteration 200: -8.60306515156377\n",
      "Cost after iteration 300: -8.60306515156377\n",
      "Cost after iteration 400: -8.60306515156377\n",
      "Cost after iteration 500: -8.60306515156377\n",
      "Cost after iteration 600: -8.60306515156377\n",
      "Cost after iteration 700: -8.60306515156377\n",
      "Cost after iteration 800: -8.60306515156377\n",
      "Cost after iteration 900: -8.60306515156377\n",
      "Cost after iteration 1000: -8.60306515156377\n",
      "Cost after iteration 1100: -8.60306515156377\n",
      "Cost after iteration 1200: -8.60306515156377\n",
      "Cost after iteration 1300: -8.60306515156377\n",
      "Cost after iteration 1400: -8.60306515156377\n",
      "Cost after iteration 1500: -8.60306515156377\n",
      "Cost after iteration 1600: -8.60306515156377\n",
      "Cost after iteration 1700: -8.60306515156377\n",
      "Cost after iteration 1800: -8.60306515156377\n",
      "Cost after iteration 1900: -8.60306515156377\n",
      "Cost after iteration 2000: -8.60306515156377\n",
      "Cost after iteration 2100: -8.60306515156377\n",
      "Cost after iteration 2200: -8.60306515156377\n",
      "Cost after iteration 2300: -8.60306515156377\n",
      "Cost after iteration 2400: -8.60306515156377\n",
      "Cost after iteration 2500: -8.60306515156377\n",
      "Cost after iteration 2600: -8.60306515156377\n",
      "Cost after iteration 2700: -8.60306515156377\n",
      "Cost after iteration 2800: -8.60306515156377\n",
      "Cost after iteration 2900: -8.60306515156377\n",
      "Cost after iteration 3000: -8.60306515156377\n",
      "Cost after iteration 3100: -8.60306515156377\n",
      "Cost after iteration 3200: -8.60306515156377\n",
      "Cost after iteration 3300: -8.60306515156377\n",
      "Cost after iteration 3400: -8.60306515156377\n",
      "Cost after iteration 3500: -8.60306515156377\n",
      "Cost after iteration 3600: -8.60306515156377\n",
      "Cost after iteration 3700: -8.60306515156377\n",
      "Cost after iteration 3800: -8.60306515156377\n",
      "Cost after iteration 3900: -8.60306515156377\n",
      "Cost after iteration 4000: -8.60306515156377\n",
      "Cost after iteration 4100: -8.60306515156377\n",
      "Cost after iteration 4200: -8.60306515156377\n",
      "Cost after iteration 4300: -8.60306515156377\n",
      "Cost after iteration 4400: -8.60306515156377\n",
      "Cost after iteration 4500: -8.60306515156377\n",
      "Cost after iteration 4600: -8.60306515156377\n",
      "Cost after iteration 4700: -8.60306515156377\n",
      "Cost after iteration 4800: -8.60306515156377\n",
      "Cost after iteration 4900: -8.60306515156377\n",
      "Cost after iteration 5000: -8.60306515156377\n",
      "Cost after iteration 5100: -8.60306515156377\n",
      "Cost after iteration 5200: -8.60306515156377\n",
      "Cost after iteration 5300: -8.60306515156377\n",
      "Cost after iteration 5400: -8.60306515156377\n",
      "Cost after iteration 5500: -8.60306515156377\n",
      "Cost after iteration 5600: -8.60306515156377\n",
      "Cost after iteration 5700: -8.60306515156377\n",
      "Cost after iteration 5800: -8.60306515156377\n",
      "Cost after iteration 5900: -8.60306515156377\n",
      "Cost after iteration 6000: -8.60306515156377\n",
      "Cost after iteration 6100: -8.60306515156377\n",
      "Cost after iteration 6200: -8.60306515156377\n",
      "Cost after iteration 6300: -8.60306515156377\n",
      "Cost after iteration 6400: -8.60306515156377\n",
      "Cost after iteration 6500: -8.60306515156377\n",
      "Cost after iteration 6600: -8.60306515156377\n",
      "Cost after iteration 6700: -8.60306515156377\n",
      "Cost after iteration 6800: -8.60306515156377\n",
      "Cost after iteration 6900: -8.60306515156377\n",
      "Cost after iteration 7000: -8.60306515156377\n",
      "Cost after iteration 7100: -8.60306515156377\n",
      "Cost after iteration 7200: -8.60306515156377\n",
      "Cost after iteration 7300: -8.60306515156377\n",
      "Cost after iteration 7400: -8.60306515156377\n",
      "Cost after iteration 7500: -8.60306515156377\n",
      "Cost after iteration 7600: -8.60306515156377\n",
      "Cost after iteration 7700: -8.60306515156377\n",
      "Cost after iteration 7800: -8.60306515156377\n",
      "Cost after iteration 7900: -8.60306515156377\n",
      "Cost after iteration 8000: -8.60306515156377\n",
      "Cost after iteration 8100: -8.60306515156377\n",
      "Cost after iteration 8200: -8.60306515156377\n",
      "Cost after iteration 8300: -8.60306515156377\n",
      "Cost after iteration 8400: -8.60306515156377\n",
      "Cost after iteration 8500: -8.60306515156377\n",
      "Cost after iteration 8600: -8.60306515156377\n",
      "Cost after iteration 8700: -8.60306515156377\n",
      "Cost after iteration 8800: -8.60306515156377\n",
      "Cost after iteration 8900: -8.60306515156377\n",
      "Cost after iteration 9000: -8.60306515156377\n",
      "Cost after iteration 9100: -8.60306515156377\n",
      "Cost after iteration 9200: -8.60306515156377\n",
      "Cost after iteration 9300: -8.60306515156377\n",
      "Cost after iteration 9400: -8.60306515156377\n",
      "Cost after iteration 9500: -8.60306515156377\n",
      "Cost after iteration 9600: -8.60306515156377\n",
      "Cost after iteration 9700: -8.60306515156377\n",
      "Cost after iteration 9800: -8.60306515156377\n",
      "Cost after iteration 9900: -8.60306515156377\n",
      "Cost after iteration 10000: -8.60306515156377\n",
      "Cost after iteration 10100: -8.60306515156377\n",
      "Cost after iteration 10200: -8.60306515156377\n",
      "Cost after iteration 10300: -8.60306515156377\n",
      "Cost after iteration 10400: -8.60306515156377\n",
      "Cost after iteration 10500: -8.60306515156377\n",
      "Cost after iteration 10600: -8.60306515156377\n",
      "Cost after iteration 10700: -8.60306515156377\n",
      "Cost after iteration 10800: -8.60306515156377\n",
      "Cost after iteration 10900: -8.60306515156377\n",
      "Cost after iteration 11000: -8.60306515156377\n",
      "Cost after iteration 11100: -8.60306515156377\n",
      "Cost after iteration 11200: -8.60306515156377\n",
      "Cost after iteration 11300: -8.60306515156377\n",
      "Cost after iteration 11400: -8.60306515156377\n",
      "Cost after iteration 11500: -8.60306515156377\n",
      "Cost after iteration 11600: -8.60306515156377\n",
      "Cost after iteration 11700: -8.60306515156377\n",
      "Cost after iteration 11800: -8.60306515156377\n",
      "Cost after iteration 11900: -8.60306515156377\n",
      "Cost after iteration 12000: -8.60306515156377\n",
      "Cost after iteration 12100: -8.60306515156377\n",
      "Cost after iteration 12200: -8.60306515156377\n",
      "Cost after iteration 12300: -8.60306515156377\n",
      "Cost after iteration 12400: -8.60306515156377\n",
      "Cost after iteration 12500: -8.60306515156377\n",
      "Cost after iteration 12600: -8.60306515156377\n",
      "Cost after iteration 12700: -8.60306515156377\n",
      "Cost after iteration 12800: -8.60306515156377\n",
      "Cost after iteration 12900: -8.60306515156377\n",
      "Cost after iteration 13000: -8.60306515156377\n",
      "Cost after iteration 13100: -8.60306515156377\n",
      "Cost after iteration 13200: -8.60306515156377\n",
      "Cost after iteration 13300: -8.60306515156377\n",
      "Cost after iteration 13400: -8.60306515156377\n",
      "Cost after iteration 13500: -8.60306515156377\n",
      "Cost after iteration 13600: -8.60306515156377\n",
      "Cost after iteration 13700: -8.60306515156377\n",
      "Cost after iteration 13800: -8.60306515156377\n",
      "Cost after iteration 13900: -8.60306515156377\n",
      "Cost after iteration 14000: -8.60306515156377\n",
      "Cost after iteration 14100: -8.60306515156377\n",
      "Cost after iteration 14200: -8.60306515156377\n",
      "Cost after iteration 14300: -8.60306515156377\n",
      "Cost after iteration 14400: -8.60306515156377\n",
      "Cost after iteration 14500: -8.60306515156377\n",
      "Cost after iteration 14600: -8.60306515156377\n",
      "Cost after iteration 14700: -8.60306515156377\n",
      "Cost after iteration 14800: -8.60306515156377\n",
      "Cost after iteration 14900: -8.60306515156377\n",
      "Cost after iteration 15000: -8.60306515156377\n",
      "Cost after iteration 15100: -8.60306515156377\n",
      "Cost after iteration 15200: -8.60306515156377\n",
      "Cost after iteration 15300: -8.60306515156377\n",
      "Cost after iteration 15400: -8.60306515156377\n",
      "Cost after iteration 15500: -8.60306515156377\n",
      "Cost after iteration 15600: -8.60306515156377\n",
      "Cost after iteration 15700: -8.60306515156377\n",
      "Cost after iteration 15800: -8.60306515156377\n",
      "Cost after iteration 15900: -8.60306515156377\n",
      "Cost after iteration 16000: -8.60306515156377\n",
      "Cost after iteration 16100: -8.60306515156377\n",
      "Cost after iteration 16200: -8.60306515156377\n",
      "Cost after iteration 16300: -8.60306515156377\n",
      "Cost after iteration 16400: -8.60306515156377\n",
      "Cost after iteration 16500: -8.60306515156377\n",
      "Cost after iteration 16600: -8.60306515156377\n",
      "Cost after iteration 16700: -8.60306515156377\n",
      "Cost after iteration 16800: -8.60306515156377\n",
      "Cost after iteration 16900: -8.60306515156377\n",
      "Cost after iteration 17000: -8.60306515156377\n",
      "Cost after iteration 17100: -8.60306515156377\n",
      "Cost after iteration 17200: -8.60306515156377\n",
      "Cost after iteration 17300: -8.60306515156377\n",
      "Cost after iteration 17400: -8.60306515156377\n",
      "Cost after iteration 17500: -8.60306515156377\n",
      "Cost after iteration 17600: -8.60306515156377\n",
      "Cost after iteration 17700: -8.60306515156377\n",
      "Cost after iteration 17800: -8.60306515156377\n",
      "Cost after iteration 17900: -8.60306515156377\n",
      "Cost after iteration 18000: -8.60306515156377\n",
      "Cost after iteration 18100: -8.60306515156377\n",
      "Cost after iteration 18200: -8.60306515156377\n",
      "Cost after iteration 18300: -8.60306515156377\n",
      "Cost after iteration 18400: -8.60306515156377\n",
      "Cost after iteration 18500: -8.60306515156377\n",
      "Cost after iteration 18600: -8.60306515156377\n",
      "Cost after iteration 18700: -8.60306515156377\n",
      "Cost after iteration 18800: -8.60306515156377\n",
      "Cost after iteration 18900: -8.60306515156377\n",
      "Cost after iteration 19000: -8.60306515156377\n",
      "Cost after iteration 19100: -8.60306515156377\n",
      "Cost after iteration 19200: -8.60306515156377\n",
      "Cost after iteration 19300: -8.60306515156377\n",
      "Cost after iteration 19400: -8.60306515156377\n",
      "Cost after iteration 19500: -8.60306515156377\n",
      "Cost after iteration 19600: -8.60306515156377\n",
      "Cost after iteration 19700: -8.60306515156377\n",
      "Cost after iteration 19800: -8.60306515156377\n",
      "Cost after iteration 19900: -8.60306515156377\n",
      "Cost after iteration 20000: -8.60306515156377\n",
      "Cost after iteration 20100: -8.60306515156377\n",
      "Cost after iteration 20200: -8.60306515156377\n",
      "Cost after iteration 20300: -8.60306515156377\n",
      "Cost after iteration 20400: -8.60306515156377\n",
      "Cost after iteration 20500: -8.60306515156377\n",
      "Cost after iteration 20600: -8.60306515156377\n",
      "Cost after iteration 20700: -8.60306515156377\n",
      "Cost after iteration 20800: -8.60306515156377\n",
      "Cost after iteration 20900: -8.60306515156377\n",
      "Cost after iteration 21000: -8.60306515156377\n",
      "Cost after iteration 21100: -8.60306515156377\n",
      "Cost after iteration 21200: -8.60306515156377\n",
      "Cost after iteration 21300: -8.60306515156377\n",
      "Cost after iteration 21400: -8.60306515156377\n",
      "Cost after iteration 21500: -8.60306515156377\n",
      "Cost after iteration 21600: -8.60306515156377\n",
      "Cost after iteration 21700: -8.60306515156377\n",
      "Cost after iteration 21800: -8.60306515156377\n",
      "Cost after iteration 21900: -8.60306515156377\n",
      "Cost after iteration 22000: -8.60306515156377\n",
      "Cost after iteration 22100: -8.60306515156377\n",
      "Cost after iteration 22200: -8.60306515156377\n",
      "Cost after iteration 22300: -8.60306515156377\n",
      "Cost after iteration 22400: -8.60306515156377\n",
      "Cost after iteration 22500: -8.60306515156377\n",
      "Cost after iteration 22600: -8.60306515156377\n",
      "Cost after iteration 22700: -8.60306515156377\n",
      "Cost after iteration 22800: -8.60306515156377\n",
      "Cost after iteration 22900: -8.60306515156377\n",
      "Cost after iteration 23000: -8.60306515156377\n",
      "Cost after iteration 23100: -8.60306515156377\n",
      "Cost after iteration 23200: -8.60306515156377\n",
      "Cost after iteration 23300: -8.60306515156377\n",
      "Cost after iteration 23400: -8.60306515156377\n",
      "Cost after iteration 23500: -8.60306515156377\n",
      "Cost after iteration 23600: -8.60306515156377\n",
      "Cost after iteration 23700: -8.60306515156377\n",
      "Cost after iteration 23800: -8.60306515156377\n",
      "Cost after iteration 23900: -8.60306515156377\n",
      "Cost after iteration 24000: -8.60306515156377\n",
      "Cost after iteration 24100: -8.60306515156377\n",
      "Cost after iteration 24200: -8.60306515156377\n",
      "Cost after iteration 24300: -8.60306515156377\n",
      "Cost after iteration 24400: -8.60306515156377\n",
      "Cost after iteration 24500: -8.60306515156377\n",
      "Cost after iteration 24600: -8.60306515156377\n",
      "Cost after iteration 24700: -8.60306515156377\n",
      "Cost after iteration 24800: -8.60306515156377\n",
      "Cost after iteration 24900: -8.60306515156377\n",
      "Cost after iteration 24999: -8.60306515156377\n"
     ]
    }
   ],
   "source": [
    "parameters, costs = L_layer_model(X_train_transposed, y_train_transposed, layers_dims, num_iterations = 25000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
